{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b539fe5",
   "metadata": {},
   "source": [
    "# Multimodal Models & AI Communication\n",
    "\n",
    "This notebook covers:\n",
    "- **LMM**: Large Multimodal Models\n",
    "- **MLLM**: Multimodal Large Language Models\n",
    "- **Communication**: MCP, A2A, A2P protocols\n",
    "- **Multi-Agent Systems**: Practical examples\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e54197",
   "metadata": {},
   "source": [
    "# Part 1: LMM & MLLM - Multimodal Models\n",
    "\n",
    "## Difference:\n",
    "- **MLLM**: LLM extended with multimodal inputs (text output mainly)\n",
    "- **LMM**: True multimodal (can output multiple modalities)\n",
    "\n",
    "## Examples:\n",
    "- **MLLM**: GPT-4V, Claude 3\n",
    "- **LMM**: Gemini Ultra, GPT-4o (audio + video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6985e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai anthropic pillow requests matplotlib soundfile -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857fae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "print(\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f9931b",
   "metadata": {},
   "source": [
    "## Example 1: Image + Text → Text (MLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18140b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multimodal_query(image_url, text_query):\n",
    "    \"\"\"Query with image and text\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": text_query},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=300\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example\n",
    "image_url = \"https://images.unsplash.com/photo-1517849845537-4d257902454a?w=600\"\n",
    "query = \"Describe this image and suggest a creative caption for social media.\"\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Response:\")\n",
    "print(multimodal_query(image_url, query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33997c2d",
   "metadata": {},
   "source": [
    "## Example 2: Multiple Images Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c7370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_multiple_images(image_urls, query):\n",
    "    \"\"\"Analyze multiple images together\"\"\"\n",
    "    content = [{\"type\": \"text\", \"text\": query}]\n",
    "    \n",
    "    for url in image_urls:\n",
    "        content.append({\"type\": \"image_url\", \"image_url\": {\"url\": url}})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=[{\"role\": \"user\", \"content\": content}],\n",
    "        max_tokens=400\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Compare multiple images\n",
    "urls = [\n",
    "    \"https://images.unsplash.com/photo-1517849845537-4d257902454a?w=400\",\n",
    "    \"https://images.unsplash.com/photo-1548199973-03cce0bbc87b?w=400\"\n",
    "]\n",
    "\n",
    "query = \"Compare these images. What are the similarities and key differences?\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Analysis:\")\n",
    "print(compare_multiple_images(urls, query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc74f2",
   "metadata": {},
   "source": [
    "## Example 3: Document Understanding (Image + Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eaeb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_document(document_image_url):\n",
    "    \"\"\"Extract and analyze document content\"\"\"\n",
    "    query = \"\"\"Analyze this document and provide:\n",
    "    1. Document type\n",
    "    2. Key information extracted\n",
    "    3. Summary of main points\n",
    "    4. Any action items or important dates\"\"\"\n",
    "    \n",
    "    return multimodal_query(document_image_url, query)\n",
    "\n",
    "print(\"Document Understanding Capabilities:\\n\")\n",
    "print(\"✓ Invoice processing\")\n",
    "print(\"✓ Receipt scanning\")\n",
    "print(\"✓ Form extraction\")\n",
    "print(\"✓ Chart/graph analysis\")\n",
    "print(\"✓ Presentation slides\")\n",
    "print(\"✓ Medical reports (with disclaimers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae18b0de",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: AI Communication Protocols\n",
    "\n",
    "## Three Main Patterns:\n",
    "1. **MCP** (Model Context Protocol): AI ↔ Tools/Data\n",
    "2. **A2A** (Agent-to-Agent): AI ↔ AI\n",
    "3. **A2P** (Agent-to-Person): AI ↔ Human"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe14427a",
   "metadata": {},
   "source": [
    "## Example 4: MCP - Model Context Protocol Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fecf3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate MCP server providing tools to AI\n",
    "class MCPServer:\n",
    "    \"\"\"Simulated MCP Server providing tools\"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.tools = {}\n",
    "    \n",
    "    def register_tool(self, name, description, function):\n",
    "        \"\"\"Register a tool\"\"\"\n",
    "        self.tools[name] = {\n",
    "            \"description\": description,\n",
    "            \"function\": function\n",
    "        }\n",
    "    \n",
    "    def list_tools(self):\n",
    "        \"\"\"List available tools\"\"\"\n",
    "        return [\n",
    "            {\"name\": name, \"description\": info[\"description\"]}\n",
    "            for name, info in self.tools.items()\n",
    "        ]\n",
    "    \n",
    "    def call_tool(self, tool_name, **kwargs):\n",
    "        \"\"\"Execute a tool\"\"\"\n",
    "        if tool_name in self.tools:\n",
    "            return self.tools[tool_name][\"function\"](**kwargs)\n",
    "        return {\"error\": \"Tool not found\"}\n",
    "\n",
    "# Create MCP servers\n",
    "database_server = MCPServer(\"database\")\n",
    "filesystem_server = MCPServer(\"filesystem\")\n",
    "\n",
    "# Register tools\n",
    "database_server.register_tool(\n",
    "    \"query_users\",\n",
    "    \"Query user database\",\n",
    "    lambda limit=10: {\"users\": [f\"user_{i}\" for i in range(limit)]}\n",
    ")\n",
    "\n",
    "filesystem_server.register_tool(\n",
    "    \"read_file\",\n",
    "    \"Read file contents\",\n",
    "    lambda path: {\"content\": f\"Contents of {path}\"}\n",
    ")\n",
    "\n",
    "print(\"MCP Servers Available:\\n\")\n",
    "print(\"1. Database Server\")\n",
    "for tool in database_server.list_tools():\n",
    "    print(f\"   - {tool['name']}: {tool['description']}\")\n",
    "\n",
    "print(\"\\n2. Filesystem Server\")\n",
    "for tool in filesystem_server.list_tools():\n",
    "    print(f\"   - {tool['name']}: {tool['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eede8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate AI using MCP tools\n",
    "class AIWithMCP:\n",
    "    \"\"\"AI agent that can use MCP tools\"\"\"\n",
    "    \n",
    "    def __init__(self, mcp_servers):\n",
    "        self.servers = mcp_servers\n",
    "    \n",
    "    def process_request(self, user_request):\n",
    "        \"\"\"Process user request using available tools\"\"\"\n",
    "        print(f\"User Request: {user_request}\\n\")\n",
    "        \n",
    "        # Simulate AI deciding which tools to use\n",
    "        if \"users\" in user_request.lower():\n",
    "            print(\"AI: I'll query the database for user information...\")\n",
    "            result = self.servers[\"database\"].call_tool(\"query_users\", limit=5)\n",
    "            print(f\"Result: {result}\")\n",
    "            return f\"Found {len(result['users'])} users: {', '.join(result['users'])}\"\n",
    "        \n",
    "        elif \"file\" in user_request.lower():\n",
    "            print(\"AI: I'll read the file...\")\n",
    "            result = self.servers[\"filesystem\"].call_tool(\"read_file\", path=\"/data/report.txt\")\n",
    "            print(f\"Result: {result}\")\n",
    "            return result['content']\n",
    "        \n",
    "        return \"I need more specific instructions.\"\n",
    "\n",
    "# Test AI with MCP\n",
    "ai = AIWithMCP({\n",
    "    \"database\": database_server,\n",
    "    \"filesystem\": filesystem_server\n",
    "})\n",
    "\n",
    "requests = [\n",
    "    \"Get the list of users from the database\",\n",
    "    \"Read the file at /data/report.txt\"\n",
    "]\n",
    "\n",
    "for req in requests:\n",
    "    print(\"=\" * 60)\n",
    "    response = ai.process_request(req)\n",
    "    print(f\"\\nAI Response: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5338afb8",
   "metadata": {},
   "source": [
    "## Example 5: A2A - Agent-to-Agent Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b801be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"Base agent class for A2A communication\"\"\"\n",
    "    \n",
    "    def __init__(self, name, role):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.inbox = []\n",
    "    \n",
    "    def send_message(self, to_agent, message_type, content):\n",
    "        \"\"\"Send message to another agent\"\"\"\n",
    "        message = {\n",
    "            \"from\": self.name,\n",
    "            \"to\": to_agent.name,\n",
    "            \"type\": message_type,\n",
    "            \"content\": content,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        to_agent.receive_message(message)\n",
    "        return message\n",
    "    \n",
    "    def receive_message(self, message):\n",
    "        \"\"\"Receive message from another agent\"\"\"\n",
    "        self.inbox.append(message)\n",
    "    \n",
    "    def process_messages(self):\n",
    "        \"\"\"Process received messages\"\"\"\n",
    "        for message in self.inbox:\n",
    "            self.handle_message(message)\n",
    "        self.inbox = []\n",
    "    \n",
    "    def handle_message(self, message):\n",
    "        \"\"\"Override in subclasses\"\"\"\n",
    "        pass\n",
    "\n",
    "# Specialized agents\n",
    "class ResearchAgent(Agent):\n",
    "    def handle_message(self, message):\n",
    "        if message['type'] == 'research_request':\n",
    "            print(f\"\\n{self.name}: Researching {message['content']['topic']}...\")\n",
    "            return {\n",
    "                \"findings\": f\"Research complete on {message['content']['topic']}\",\n",
    "                \"sources\": 10\n",
    "            }\n",
    "\n",
    "class WriterAgent(Agent):\n",
    "    def handle_message(self, message):\n",
    "        if message['type'] == 'write_request':\n",
    "            print(f\"\\n{self.name}: Writing about {message['content']['topic']}...\")\n",
    "            return {\n",
    "                \"article\": f\"Article written about {message['content']['topic']}\",\n",
    "                \"word_count\": 500\n",
    "            }\n",
    "\n",
    "class EditorAgent(Agent):\n",
    "    def handle_message(self, message):\n",
    "        if message['type'] == 'edit_request':\n",
    "            print(f\"\\n{self.name}: Editing content...\")\n",
    "            return {\n",
    "                \"edited\": True,\n",
    "                \"improvements\": [\"Grammar\", \"Clarity\", \"Flow\"]\n",
    "            }\n",
    "\n",
    "print(\"✓ Agent classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c99648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-agent system\n",
    "research_agent = ResearchAgent(\"Research-Bot\", \"Researcher\")\n",
    "writer_agent = WriterAgent(\"Writer-Bot\", \"Writer\")\n",
    "editor_agent = EditorAgent(\"Editor-Bot\", \"Editor\")\n",
    "\n",
    "# Simulate workflow\n",
    "print(\"Multi-Agent Workflow: Creating an Article\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Request research\n",
    "msg1 = research_agent.send_message(\n",
    "    research_agent,\n",
    "    \"research_request\",\n",
    "    {\"topic\": \"Artificial Intelligence\"}\n",
    ")\n",
    "print(f\"\\nMessage 1: {msg1['from']} → {msg1['to']}\")\n",
    "print(f\"Type: {msg1['type']}\")\n",
    "print(f\"Content: {msg1['content']}\")\n",
    "research_agent.process_messages()\n",
    "\n",
    "# Step 2: Request writing\n",
    "msg2 = writer_agent.send_message(\n",
    "    writer_agent,\n",
    "    \"write_request\",\n",
    "    {\"topic\": \"AI Applications\", \"research\": \"...\"}\n",
    ")\n",
    "print(f\"\\nMessage 2: {msg2['from']} → {msg2['to']}\")\n",
    "print(f\"Type: {msg2['type']}\")\n",
    "writer_agent.process_messages()\n",
    "\n",
    "# Step 3: Request editing\n",
    "msg3 = editor_agent.send_message(\n",
    "    editor_agent,\n",
    "    \"edit_request\",\n",
    "    {\"article\": \"...\", \"style_guide\": \"AP\"}\n",
    ")\n",
    "print(f\"\\nMessage 3: {msg3['from']} → {msg3['to']}\")\n",
    "print(f\"Type: {msg3['type']}\")\n",
    "editor_agent.process_messages()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\n✓ Article creation complete via agent collaboration!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e02f0e",
   "metadata": {},
   "source": [
    "## Example 6: A2P - Agent-to-Person Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac9fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationalAgent:\n",
    "    \"\"\"Agent for human interaction (A2P)\"\"\"\n",
    "    \n",
    "    def __init__(self, name, personality=\"helpful\"):\n",
    "        self.name = name\n",
    "        self.personality = personality\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def chat(self, user_message):\n",
    "        \"\"\"Respond to user message\"\"\"\n",
    "        self.conversation_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"message\": user_message\n",
    "        })\n",
    "        \n",
    "        # Simulate response generation\n",
    "        response = self._generate_response(user_message)\n",
    "        \n",
    "        self.conversation_history.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"message\": response\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _generate_response(self, message):\n",
    "        \"\"\"Generate contextual response\"\"\"\n",
    "        # Simplified response logic\n",
    "        if \"hello\" in message.lower():\n",
    "            return f\"Hello! I'm {self.name}, your {self.personality} assistant. How can I help you today?\"\n",
    "        elif \"help\" in message.lower():\n",
    "            return \"I can help you with various tasks. What would you like to know?\"\n",
    "        elif \"?\" in message:\n",
    "            return f\"That's a great question! Let me help you with that...\"\n",
    "        else:\n",
    "            return \"I understand. Let me assist you with that.\"\n",
    "    \n",
    "    def get_history(self):\n",
    "        \"\"\"Get conversation history\"\"\"\n",
    "        return self.conversation_history\n",
    "\n",
    "# Create conversational agent\n",
    "assistant = ConversationalAgent(\"AI-Assistant\", \"friendly and helpful\")\n",
    "\n",
    "# Simulate conversation\n",
    "print(\"A2P Communication Example\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "conversation = [\n",
    "    \"Hello!\",\n",
    "    \"I need help with Python programming\",\n",
    "    \"What are the best practices for writing clean code?\",\n",
    "    \"Thank you!\"\n",
    "]\n",
    "\n",
    "for user_msg in conversation:\n",
    "    print(f\"\\nUser: {user_msg}\")\n",
    "    response = assistant.chat(user_msg)\n",
    "    print(f\"{assistant.name}: {response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"\\nConversation turns: {len(assistant.get_history()) // 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9450c0",
   "metadata": {},
   "source": [
    "## Example 7: Complete Multi-Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f0917",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coordinator:\n",
    "    \"\"\"Coordinates multiple agents\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.agents = {}\n",
    "    \n",
    "    def register_agent(self, agent):\n",
    "        \"\"\"Register an agent\"\"\"\n",
    "        self.agents[agent.name] = agent\n",
    "    \n",
    "    def orchestrate_task(self, task_description):\n",
    "        \"\"\"Coordinate agents to complete a task\"\"\"\n",
    "        print(f\"\\nCoordinator: Starting task - {task_description}\\n\")\n",
    "        \n",
    "        # Break down task and assign to agents\n",
    "        steps = [\n",
    "            (\"Research-Bot\", \"research_request\", {\"topic\": task_description}),\n",
    "            (\"Writer-Bot\", \"write_request\", {\"topic\": task_description}),\n",
    "            (\"Editor-Bot\", \"edit_request\", {\"content\": \"draft\"})\n",
    "        ]\n",
    "        \n",
    "        results = []\n",
    "        for agent_name, msg_type, content in steps:\n",
    "            if agent_name in self.agents:\n",
    "                agent = self.agents[agent_name]\n",
    "                print(f\"→ Assigning to {agent_name}...\")\n",
    "                agent.receive_message({\n",
    "                    \"from\": \"Coordinator\",\n",
    "                    \"to\": agent_name,\n",
    "                    \"type\": msg_type,\n",
    "                    \"content\": content\n",
    "                })\n",
    "                agent.process_messages()\n",
    "                results.append(f\"{agent_name} completed\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Create coordinator and register agents\n",
    "coordinator = Coordinator()\n",
    "coordinator.register_agent(research_agent)\n",
    "coordinator.register_agent(writer_agent)\n",
    "coordinator.register_agent(editor_agent)\n",
    "\n",
    "print(\"Complete Multi-Agent System Demo\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Execute complex task\n",
    "task = \"Write an article about Machine Learning applications\"\n",
    "results = coordinator.orchestrate_task(task)\n",
    "\n",
    "print(\"\\nTask Results:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"  {i}. {result}\")\n",
    "\n",
    "print(\"\\n✓ Multi-agent task completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb580430",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "## Multimodal Models:\n",
    "\n",
    "### MLLM (Multimodal LLM)\n",
    "- ✅ Input: Text + Images + Audio\n",
    "- ✅ Output: Primarily text\n",
    "- ✅ Examples: GPT-4V, Claude 3, Gemini Pro Vision\n",
    "- ✅ Use: Visual Q&A, document understanding, image analysis\n",
    "\n",
    "### LMM (Large Multimodal Model)\n",
    "- ✅ Input: Any modality\n",
    "- ✅ Output: Multiple modalities\n",
    "- ✅ Examples: Gemini Ultra, GPT-4o\n",
    "- ✅ Use: Complex multi-modal tasks, video understanding\n",
    "\n",
    "## Communication Protocols:\n",
    "\n",
    "### 1. MCP (Model Context Protocol)\n",
    "```\n",
    "AI Model ↔ Tools/Resources\n",
    "```\n",
    "- **Purpose**: Standardized tool access\n",
    "- **Use**: Databases, filesystems, APIs\n",
    "- **Benefit**: Portable, reusable integrations\n",
    "\n",
    "### 2. A2A (Agent-to-Agent)\n",
    "```\n",
    "AI Agent ↔ AI Agent\n",
    "```\n",
    "- **Purpose**: AI collaboration\n",
    "- **Use**: Multi-agent workflows\n",
    "- **Benefit**: Specialized expertise, parallel processing\n",
    "\n",
    "### 3. A2P (Agent-to-Person)\n",
    "```\n",
    "AI Agent ↔ Human\n",
    "```\n",
    "- **Purpose**: Human-AI interaction\n",
    "- **Use**: Chatbots, assistants, interfaces\n",
    "- **Benefit**: Natural language communication\n",
    "\n",
    "## Key Patterns:\n",
    "\n",
    "| Pattern | When to Use | Example |\n",
    "|---------|-------------|----------|\n",
    "| **Single Agent** | Simple tasks | Basic chatbot |\n",
    "| **Multi-Agent** | Complex workflows | Research + Write + Edit |\n",
    "| **With MCP** | Need external data | Database queries |\n",
    "| **Orchestrated** | Coordinated tasks | Project management |\n",
    "\n",
    "## Real-World Applications:\n",
    "\n",
    "1. **Content Creation Pipeline**\n",
    "   - Research Agent → Writer Agent → Editor Agent → Publisher\n",
    "\n",
    "2. **Customer Support**\n",
    "   - Reception → Data Lookup (MCP) → Policy Check → Response\n",
    "\n",
    "3. **Software Development**\n",
    "   - Architect → Developer → Tester → Deployment\n",
    "\n",
    "4. **Data Analysis**\n",
    "   - Data Collection (MCP) → Analysis → Visualization → Reporting\n",
    "\n",
    "## Next Steps:\n",
    "- Build your own multi-agent system\n",
    "- Implement MCP servers for your tools\n",
    "- Explore advanced orchestration patterns\n",
    "- Combine multiple AI models for complex tasks"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
