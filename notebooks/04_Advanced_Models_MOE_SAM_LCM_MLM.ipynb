{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd5379bb",
   "metadata": {},
   "source": [
    "# Advanced AI Models: MOE, SAM, LCM, MLM Examples\n",
    "\n",
    "This notebook covers specialized AI architectures:\n",
    "- **MOE**: Mixture of Experts\n",
    "- **SAM**: Segment Anything Model\n",
    "- **LCM**: Latent Consistency Model\n",
    "- **MLM**: Masked Language Model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05174774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers torch diffusers accelerate segment-anything pillow matplotlib numpy opencv-python -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ee1c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d28c6b",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: MOE - Mixture of Experts\n",
    "\n",
    "## What is MOE?\n",
    "- **Architecture**: Multiple expert sub-models with a router\n",
    "- **Efficiency**: Only activates 2-4 experts per token\n",
    "- **Size**: 8x7B = 56B total, but uses only ~14B at inference\n",
    "- **Example**: Mixtral 8x7B\n",
    "\n",
    "### How it works:\n",
    "```\n",
    "Input Token → Router → Selects 2 Experts → Process → Output\n",
    "               ↓\n",
    "        [Expert 1] [Expert 2] [Expert 3] [Expert 4]\n",
    "        [Expert 5] [Expert 6] [Expert 7] [Expert 8]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdc2d41",
   "metadata": {},
   "source": [
    "## Example 1: Using Mixtral 8x7B (MOE Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load Mixtral (MOE architecture)\n",
    "print(\"Loading Mixtral 8x7B...\")\n",
    "print(\"Note: This requires significant GPU memory (~90GB unquantized)\")\n",
    "print(\"Using 4-bit quantization to reduce memory...\\n\")\n",
    "\n",
    "model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "# For demo purposes - would need GPU\n",
    "print(\"MOE Architecture Details:\")\n",
    "print(\"- Total parameters: 46.7B\")\n",
    "print(\"- Active per token: ~12.9B\")\n",
    "print(\"- Number of experts: 8\")\n",
    "print(\"- Experts used per token: 2\")\n",
    "print(\"- Result: Similar quality to 70B model with 2x efficiency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcd7b2e",
   "metadata": {},
   "source": [
    "## Example 2: MOE Concept Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40455f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate MOE routing logic\n",
    "class SimpleMOE:\n",
    "    \"\"\"Simplified MOE demonstration\"\"\"\n",
    "    \n",
    "    def __init__(self, num_experts=8):\n",
    "        self.num_experts = num_experts\n",
    "        self.expert_names = [\n",
    "            \"Math Expert\", \"Code Expert\", \"Science Expert\", \"History Expert\",\n",
    "            \"Language Expert\", \"Creative Expert\", \"Logic Expert\", \"General Expert\"\n",
    "        ]\n",
    "    \n",
    "    def route(self, query):\n",
    "        \"\"\"Route query to appropriate experts\"\"\"\n",
    "        # Simplified routing based on keywords\n",
    "        keywords = {\n",
    "            0: [\"math\", \"calculate\", \"equation\", \"number\"],\n",
    "            1: [\"code\", \"program\", \"function\", \"algorithm\"],\n",
    "            2: [\"science\", \"physics\", \"chemistry\", \"biology\"],\n",
    "            3: [\"history\", \"historical\", \"past\", \"century\"],\n",
    "            4: [\"translate\", \"language\", \"grammar\"],\n",
    "            5: [\"creative\", \"story\", \"poem\", \"artistic\"],\n",
    "            6: [\"logic\", \"reasoning\", \"puzzle\"],\n",
    "            7: []  # General catch-all\n",
    "        }\n",
    "        \n",
    "        query_lower = query.lower()\n",
    "        scores = [0] * self.num_experts\n",
    "        \n",
    "        for expert_id, words in keywords.items():\n",
    "            for word in words:\n",
    "                if word in query_lower:\n",
    "                    scores[expert_id] += 1\n",
    "        \n",
    "        # Select top 2 experts\n",
    "        top_experts = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:2]\n",
    "        \n",
    "        return [self.expert_names[i] for i in top_experts]\n",
    "\n",
    "# Test the routing\n",
    "moe = SimpleMOE()\n",
    "\n",
    "queries = [\n",
    "    \"Calculate the factorial of 10\",\n",
    "    \"Write a Python function to sort a list\",\n",
    "    \"Explain photosynthesis\",\n",
    "    \"Who was the first president?\",\n",
    "    \"Write a haiku about spring\"\n",
    "]\n",
    "\n",
    "print(\"MOE Routing Demonstration:\\n\")\n",
    "for query in queries:\n",
    "    experts = moe.route(query)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Selected Experts: {', '.join(experts)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d75c7",
   "metadata": {},
   "source": [
    "## MOE Benefits\n",
    "\n",
    "```python\n",
    "# Traditional Dense Model\n",
    "model_size = 70B\n",
    "active_params = 70B  # All parameters used\n",
    "cost = HIGH\n",
    "\n",
    "# MOE Model\n",
    "model_size = 8 * 7B = 56B total\n",
    "active_params = 12.9B  # Only 2 experts active\n",
    "cost = MEDIUM\n",
    "performance = Similar to 70B!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec035fc3",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: SAM - Segment Anything Model\n",
    "\n",
    "## What is SAM?\n",
    "- **Purpose**: Universal image segmentation\n",
    "- **Input**: Image + prompt (point, box, or text)\n",
    "- **Output**: Precise object masks\n",
    "- **Provider**: Meta AI\n",
    "\n",
    "### Use Cases:\n",
    "- Object isolation\n",
    "- Background removal\n",
    "- Image editing\n",
    "- Medical imaging\n",
    "- Autonomous vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c550e6",
   "metadata": {},
   "source": [
    "## Example 3: Using SAM for Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: SAM requires specific installation\n",
    "# pip install git+https://github.com/facebookresearch/segment-anything.git\n",
    "\n",
    "print(\"SAM (Segment Anything Model) Overview:\\n\")\n",
    "print(\"Architecture:\")\n",
    "print(\"- Model size: ~600M parameters\")\n",
    "print(\"- Speed: Fast inference (~50ms per image)\")\n",
    "print(\"- Accuracy: State-of-the-art segmentation\")\n",
    "print(\"\\nPrompting Options:\")\n",
    "print(\"1. Point prompt: Click on object\")\n",
    "print(\"2. Box prompt: Draw bounding box\")\n",
    "print(\"3. Text prompt: Describe what to segment\")\n",
    "print(\"4. Automatic: Segment everything in image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10a7aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated SAM workflow\n",
    "def demonstrate_sam_workflow():\n",
    "    \"\"\"\n",
    "    Demonstrate SAM segmentation workflow\n",
    "    \"\"\"\n",
    "    print(\"SAM Workflow Example:\\n\")\n",
    "    \n",
    "    print(\"Step 1: Load image\")\n",
    "    print(\"   image = load_image('photo.jpg')\")\n",
    "    \n",
    "    print(\"\\nStep 2: Initialize SAM\")\n",
    "    print(\"   sam = SAM(checkpoint='sam_vit_h')\")\n",
    "    \n",
    "    print(\"\\nStep 3: Generate embeddings\")\n",
    "    print(\"   predictor.set_image(image)\")\n",
    "    \n",
    "    print(\"\\nStep 4: Prompt with point/box\")\n",
    "    print(\"   input_point = [500, 375]  # x, y coordinates\")\n",
    "    print(\"   input_label = 1  # 1 = foreground point\")\n",
    "    \n",
    "    print(\"\\nStep 5: Get segmentation mask\")\n",
    "    print(\"   masks, scores, logits = predictor.predict(\")\n",
    "    print(\"       point_coords=input_point,\")\n",
    "    print(\"       point_labels=input_label\")\n",
    "    print(\"   )\")\n",
    "    \n",
    "    print(\"\\nStep 6: Use mask\")\n",
    "    print(\"   - Isolate object\")\n",
    "    print(\"   - Remove background\")\n",
    "    print(\"   - Create composite\")\n",
    "    \n",
    "demonstrate_sam_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3801eed3",
   "metadata": {},
   "source": [
    "## Example 4: SAM Use Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_use_cases = {\n",
    "    \"E-commerce\": \"Remove background from product photos\",\n",
    "    \"Medical\": \"Segment organs/tumors in medical imaging\",\n",
    "    \"Photography\": \"Select and edit specific objects\",\n",
    "    \"Autonomous Vehicles\": \"Identify pedestrians, vehicles, obstacles\",\n",
    "    \"Agriculture\": \"Identify crops, diseases, pests\",\n",
    "    \"Robotics\": \"Object recognition and manipulation\",\n",
    "    \"Video Editing\": \"Rotoscoping and object isolation\",\n",
    "    \"AR/VR\": \"Real-time object segmentation\"\n",
    "}\n",
    "\n",
    "print(\"SAM Real-World Applications:\\n\")\n",
    "for industry, use in sam_use_cases.items():\n",
    "    print(f\"• {industry}: {use}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae285752",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: LCM - Latent Consistency Model\n",
    "\n",
    "## What is LCM?\n",
    "- **Purpose**: Ultra-fast image generation\n",
    "- **Speed**: 1-4 steps vs 50+ for traditional diffusion\n",
    "- **Quality**: Maintains high quality\n",
    "- **Use**: Real-time AI art generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7298a61",
   "metadata": {},
   "source": [
    "## Example 5: LCM for Fast Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a15066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "# Load LCM model\n",
    "print(\"Loading LCM (Latent Consistency Model)...\\n\")\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    \"SimianLuo/LCM_Dreamshaper_v7\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Move to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    pipe = pipe.to(\"cuda\")\n",
    "    print(\"✓ Using GPU acceleration\")\n",
    "else:\n",
    "    print(\"⚠ Running on CPU (slower)\")\n",
    "\n",
    "print(\"\\nLCM loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3619fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def generate_image_lcm(prompt, num_steps=4):\n",
    "    \"\"\"Generate image using LCM\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        num_inference_steps=num_steps,\n",
    "        guidance_scale=8.0,\n",
    "        height=512,\n",
    "        width=512\n",
    "    ).images[0]\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    return image, elapsed\n",
    "\n",
    "# Generate images\n",
    "prompts = [\n",
    "    \"A serene landscape with mountains and lake, digital art\",\n",
    "    \"A futuristic city at night, cyberpunk style\",\n",
    "    \"A cute robot reading a book, cartoon style\"\n",
    "]\n",
    "\n",
    "print(\"Generating images with LCM (4 steps):\\n\")\n",
    "\n",
    "for i, prompt in enumerate(prompts, 1):\n",
    "    print(f\"Image {i}: {prompt}\")\n",
    "    image, time_taken = generate_image_lcm(prompt)\n",
    "    print(f\"Generation time: {time_taken:.2f}s\")\n",
    "    \n",
    "    # Display image\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Prompt: {prompt[:40]}...\")\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd7ed65",
   "metadata": {},
   "source": [
    "## Example 6: LCM vs Traditional Diffusion Speed Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac0d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed comparison\n",
    "comparison = {\n",
    "    \"Method\": [\"Stable Diffusion\", \"SDXL\", \"LCM (ours)\"],\n",
    "    \"Steps\": [50, 40, 4],\n",
    "    \"Time (seconds)\": [5.2, 8.5, 0.6],\n",
    "    \"Quality\": [\"High\", \"Very High\", \"High\"]\n",
    "}\n",
    "\n",
    "print(\"Speed Comparison:\\n\")\n",
    "print(f\"{'Method':<20} {'Steps':<10} {'Time (s)':<12} {'Quality'}\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(len(comparison[\"Method\"])):\n",
    "    print(f\"{comparison['Method'][i]:<20} {comparison['Steps'][i]:<10} \"\n",
    "          f\"{comparison['Time (seconds)'][i]:<12} {comparison['Quality'][i]}\")\n",
    "\n",
    "print(\"\\n✨ LCM is 8-10x faster while maintaining quality!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcff1f5",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: MLM - Masked Language Model\n",
    "\n",
    "## What is MLM?\n",
    "- **Architecture**: BERT-style bidirectional\n",
    "- **Training**: Predict masked tokens\n",
    "- **Purpose**: Understanding > Generation\n",
    "- **Examples**: BERT, RoBERTa, ALBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c53b8f2",
   "metadata": {},
   "source": [
    "## Example 7: Using BERT (MLM) for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb40d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load BERT for sentiment analysis\n",
    "print(\"Loading BERT (Masked Language Model) for classification...\\n\")\n",
    "\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "\n",
    "print(\"✓ BERT model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183098ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis examples\n",
    "texts = [\n",
    "    \"This product is absolutely amazing! Best purchase ever!\",\n",
    "    \"Terrible quality. Very disappointed with this.\",\n",
    "    \"It's okay, nothing special but works fine.\",\n",
    "    \"I love the design but the price is too high.\",\n",
    "    \"Fast shipping and excellent customer service!\"\n",
    "]\n",
    "\n",
    "print(\"Sentiment Analysis with BERT:\\n\")\n",
    "\n",
    "for text in texts:\n",
    "    result = sentiment_analyzer(text)[0]\n",
    "    sentiment = result['label']\n",
    "    confidence = result['score']\n",
    "    \n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Sentiment: {sentiment} (confidence: {confidence:.2%})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb561a",
   "metadata": {},
   "source": [
    "## Example 8: MLM Fill-Mask Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT for fill-mask\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "\n",
    "# Examples with masked tokens\n",
    "sentences = [\n",
    "    \"The capital of France is [MASK].\",\n",
    "    \"Python is a [MASK] programming language.\",\n",
    "    \"The [MASK] is shining brightly today.\",\n",
    "    \"Artificial [MASK] is transforming technology.\"\n",
    "]\n",
    "\n",
    "print(\"Fill-Mask Task (Predicting Masked Words):\\n\")\n",
    "\n",
    "for sentence in sentences:\n",
    "    results = fill_mask(sentence, top_k=3)\n",
    "    print(f\"Input: {sentence}\\n\")\n",
    "    print(\"Top predictions:\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        word = result['token_str'].strip()\n",
    "        score = result['score']\n",
    "        print(f\"  {i}. '{word}' (confidence: {score:.2%})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01acfdd",
   "metadata": {},
   "source": [
    "## Example 9: Named Entity Recognition (NER) with MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NER pipeline\n",
    "ner = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "\n",
    "text = \"\"\"\n",
    "Apple Inc. was founded by Steve Jobs in Cupertino, California. \n",
    "The company released the iPhone in 2007, which revolutionized \n",
    "the smartphone industry. Tim Cook became CEO in 2011.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Named Entity Recognition:\\n\")\n",
    "print(f\"Text: {text}\\n\")\n",
    "\n",
    "entities = ner(text)\n",
    "\n",
    "# Group entities by type\n",
    "entity_groups = {}\n",
    "for entity in entities:\n",
    "    entity_type = entity['entity'].replace('B-', '').replace('I-', '')\n",
    "    if entity_type not in entity_groups:\n",
    "        entity_groups[entity_type] = []\n",
    "    entity_groups[entity_type].append(entity['word'])\n",
    "\n",
    "print(\"Extracted Entities:\\n\")\n",
    "for entity_type, words in entity_groups.items():\n",
    "    # Clean and deduplicate\n",
    "    clean_words = ' '.join(words).replace(' ##', '')\n",
    "    print(f\"{entity_type}: {clean_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d3f481",
   "metadata": {},
   "source": [
    "## Example 10: Question Answering with MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load QA model\n",
    "qa_model = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "context = \"\"\"\n",
    "The Transformer architecture was introduced in the paper 'Attention Is All You Need' \n",
    "by Vaswani et al. in 2017. It revolutionized natural language processing by using \n",
    "self-attention mechanisms instead of recurrent neural networks. The architecture \n",
    "consists of an encoder and decoder, each with multiple layers. BERT, GPT, and many \n",
    "modern language models are based on this architecture.\n",
    "\"\"\"\n",
    "\n",
    "questions = [\n",
    "    \"Who introduced the Transformer architecture?\",\n",
    "    \"When was the Transformer introduced?\",\n",
    "    \"What does the Transformer use instead of RNNs?\",\n",
    "    \"What models are based on Transformer architecture?\"\n",
    "]\n",
    "\n",
    "print(\"Question Answering with BERT:\\n\")\n",
    "print(f\"Context: {context}\\n\")\n",
    "print(\"Questions and Answers:\\n\")\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_model(question=question, context=context)\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"A: {result['answer']} (confidence: {result['score']:.2%})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be4de4",
   "metadata": {},
   "source": [
    "## MLM vs LLM Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb250c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLM vs LLM Comparison:\\n\")\n",
    "\n",
    "comparison = [\n",
    "    [\"Aspect\", \"MLM (BERT)\", \"LLM (GPT)\"],\n",
    "    [\"-\" * 20, \"-\" * 30, \"-\" * 30],\n",
    "    [\"Architecture\", \"Bidirectional (Encoder)\", \"Unidirectional (Decoder)\"],\n",
    "    [\"Training\", \"Masked token prediction\", \"Next token prediction\"],\n",
    "    [\"Best For\", \"Understanding & Classification\", \"Generation & Completion\"],\n",
    "    [\"Context\", \"Full sentence context\", \"Left-to-right context\"],\n",
    "    [\"Speed\", \"Fast\", \"Medium\"],\n",
    "    [\"Use Cases\", \"NER, Classification, QA\", \"Text generation, Chat\"],\n",
    "    [\"Size\", \"110M - 340M params\", \"1B - 405B params\"],\n",
    "    [\"Generation\", \"❌ Weak\", \"✅ Strong\"],\n",
    "    [\"Understanding\", \"✅ Strong\", \"✅ Strong\"]\n",
    "]\n",
    "\n",
    "for row in comparison:\n",
    "    print(f\"{row[0]:<20} {row[1]:<30} {row[2]:<30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4401a9",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "## Models Covered:\n",
    "\n",
    "### 1. MOE (Mixture of Experts)\n",
    "- ✅ Efficient scaling with expert routing\n",
    "- ✅ 8x7B model with 12B active parameters\n",
    "- ✅ Best for: Multi-domain tasks efficiently\n",
    "\n",
    "### 2. SAM (Segment Anything Model)\n",
    "- ✅ Universal image segmentation\n",
    "- ✅ Multiple prompting options\n",
    "- ✅ Best for: Object isolation, medical imaging, editing\n",
    "\n",
    "### 3. LCM (Latent Consistency Model)\n",
    "- ✅ Ultra-fast image generation (4 steps)\n",
    "- ✅ 10x faster than traditional diffusion\n",
    "- ✅ Best for: Real-time AI art, rapid prototyping\n",
    "\n",
    "### 4. MLM (Masked Language Model)\n",
    "- ✅ Bidirectional text understanding\n",
    "- ✅ Excellent for classification and NER\n",
    "- ✅ Best for: Sentiment analysis, QA, entity extraction\n",
    "\n",
    "## Key Takeaways:\n",
    "\n",
    "| Model | When to Use |\n",
    "|-------|-------------|\n",
    "| **MOE** | Need efficiency with multi-domain expertise |\n",
    "| **SAM** | Image segmentation, object isolation |\n",
    "| **LCM** | Fast image generation, real-time applications |\n",
    "| **MLM** | Text classification, NER, understanding tasks |\n",
    "\n",
    "## Next Steps:\n",
    "- Combine models for complex workflows\n",
    "- Explore LMM/MLLM for multimodal tasks\n",
    "- Learn about LAM for action-taking AI\n",
    "- Study communication protocols (MCP, A2A)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
